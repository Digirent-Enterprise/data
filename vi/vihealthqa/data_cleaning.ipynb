{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-16T16:59:27.156976Z",
     "start_time": "2023-06-16T16:59:25.192210Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = 'qrels/dev.tsv'\n",
    "file2 = 'qrels/test.tsv'\n",
    "file3 = 'qrels/train.tsv'\n",
    "\n",
    "df1 = pd.read_csv(file1, delimiter='\\t')\n",
    "df2 = pd.read_csv(file2, delimiter='\\t')\n",
    "df3 = pd.read_csv(file3, delimiter='\\t')\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3])\n",
    "\n",
    "merged_file = 'merged.tsv'\n",
    "merged_df.to_csv(merged_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def export_csv(merge_file, queries_file, corpus_file, output_file):\n",
    "    # Read merge.tsv file\n",
    "    merge_data = {}\n",
    "    with open(merge_file, 'r') as merge:\n",
    "        merge_reader = csv.reader(merge, delimiter='\\t')\n",
    "        next(merge_reader)  # Skip header row\n",
    "        for row in merge_reader:\n",
    "            query_id, corpus_id, *_ = row  # Take only the first two columns\n",
    "            merge_data[query_id] = corpus_id\n",
    "\n",
    "    # Read queries.jsonl file\n",
    "    queries_data = {}\n",
    "    with open(queries_file, 'r') as queries:\n",
    "        for line in queries:\n",
    "            query = json.loads(line)\n",
    "            queries_data[query['_id']] = query['text']\n",
    "\n",
    "    # Read corpus.jsonl file\n",
    "    corpus_data = {}\n",
    "    with open(corpus_file, 'r') as corpus:\n",
    "        for line in corpus:\n",
    "            doc = json.loads(line)\n",
    "            corpus_data[doc['_id']] = doc['text']\n",
    "\n",
    "    # Write to output CSV file\n",
    "    with open(output_file, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"Question\", \"Answer\"])\n",
    "\n",
    "        for query_id, corpus_id in merge_data.items():\n",
    "            question = queries_data.get(query_id, \"\")\n",
    "            answer = corpus_data.get(corpus_id, \"\")\n",
    "            writer.writerow([question, answer])\n",
    "\n",
    "# Usage example\n",
    "merge_file = \"merged.tsv\"\n",
    "queries_file = \"queries.jsonl\"\n",
    "corpus_file = \"corpus.jsonl\"\n",
    "output_file = \"output.csv\"\n",
    "\n",
    "export_csv(merge_file, queries_file, corpus_file, output_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T17:11:22.477768Z",
     "start_time": "2023-06-16T17:11:22.363104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
